{"cells":[{"metadata":{},"cell_type":"markdown","source":"Loading libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\nimport sklearn\nfrom sklearn import metrics\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, precision_recall_curve, auc, roc_curve, recall_score","execution_count":20,"outputs":[{"output_type":"stream","text":"/kaggle/input/metagenomics/markers2clades_DB.txt\n/kaggle/input/metagenomics/abundance_stoolsubset.txt\n/kaggle/input/metagenomics/abundance.txt\n/kaggle/input/metagenomics/marker_presence.txt\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Metaparameters\nVERBOSE = 0\nFOLDS = 5\n# show_fold_stats = True\nshow_fold_stats = False\n# test_train_split_SEED = 1970\ntest_train_split_SEED = 1971","execution_count":21,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def plot_ROC(fpr, tpr, m_name):\n    roc_auc = sklearn.metrics.auc(fpr, tpr)\n    plt.figure(figsize=(6, 6))\n    lw = 2\n    plt.plot(fpr, tpr, color='darkorange',\n             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc, alpha=0.5)\n    \n    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', alpha=0.5)\n    \n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xticks(fontsize=16)\n    plt.yticks(fontsize=16)\n    plt.grid(True)\n    plt.xlabel('False Positive Rate', fontsize=16)\n    plt.ylabel('True Positive Rate', fontsize=16)\n    plt.title('ROC for %s'%m_name, fontsize=20)\n    plt.legend(loc=\"lower right\", fontsize=16)\n    plt.show()","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pd_abundance = pd.read_csv('data/abundance.txt', sep='\\t', header=None, index_col=0, dtype=str)\npd_abundance = pd.read_csv('/kaggle/input/metagenomics/abundance_stoolsubset.txt', sep='\\t', header=None, index_col=0, dtype=str)\nind = pd_abundance.index.tolist()\ndisease = pd_abundance.loc['disease',:] \n# d_name = pd_abundance.loc['dataset_name',:] \nprint(disease.value_counts())\n# d_name.value_counts()\n\ndiseases = ['obesity', 'cirrhosis', 't2d', 'cancer']","execution_count":23,"outputs":[{"output_type":"stream","text":"n                             944\nt2d                           223\nobesity                       164\nibd_ulcerative_colitis        148\ncirrhosis                     118\nleaness                        89\nstec2-positive                 52\nimpaired_glucose_tolerance     49\ncancer                         48\nn_relative                     47\nsmall_adenoma                  26\nibd_crohn_disease              25\n -                             20\nlarge_adenoma                  13\noverweight                     10\n-                               7\nobese                           5\nunderweight                     1\nName: disease, dtype: int64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd_abundance = pd_abundance.transpose()\ncols = pd_abundance.columns.tolist()\nspecies = [x for x in cols if x.startswith('k_')]\ndescr = [x for x in cols if not x.startswith('k_')]\npd_abundance_conv = pd_abundance.copy()\npd_abundance_conv = pd_abundance_conv[species].astype('float64')\npd_abundance_conv = pd.concat([pd_abundance[descr], pd_abundance_conv], axis = 1)\n\ndata_sets = {'control':['hmp', 'hmpii'],'t2d':['WT2D','t2dmeta_long','t2dmeta_short'], 'cirrhosis' : ['Quin_gut_liver_cirrhosis'], 'cancer' : ['Zeller_fecal_colorectal_cancer'], 'obesity' : ['Chatelier_gut_obesity']}\npd_abundance_conv['disease'] = pd_abundance_conv['disease'].apply(lambda x: 'control' if ((x == 'n') or (x == 'nd') or (x == 'leaness')) else x)\ndisease1 = pd_abundance_conv.loc[:,'disease'] \npd_control = pd_abundance_conv.loc[pd_abundance_conv['disease'] == 'control']\npd_disease = pd_abundance_conv.loc[pd_abundance_conv['disease'] != 'control']\nnot_disease = [d for d in pd_disease.disease.unique().tolist() if d not in diseases] # don't consider these diseases\n\n","execution_count":24,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def disease_distinction(d, counter_d):\n    print('-' * 80)\n    print('Discriminate %s from %s'%(d,counter_d))\n    \n    skf = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\n    oof_preds = []\n    oof_aucs = []\n    oof_scores= []\n    ds_names = data_sets[d]\n    if len(ds_names) == 1:\n        pd_cont = pd_control.loc[pd_control['dataset_name'] == ds_names[0]]\n        pd_dis = pd_disease.loc[pd_disease['dataset_name'] == ds_names[0]]\n    else:\n        pd_cont = pd_control.loc[pd_control['dataset_name'] == ds_names[0]]\n        pd_dis = pd_disease.loc[(pd_disease['disease'] == d) & (pd_disease['dataset_name'] == ds_names[0])]\n        for ds in ds_names[1:]:\n            pd_cont = pd.concat([pd_cont, pd_control.loc[pd_control['dataset_name'] == ds]], axis = 0)\n            pd_dis = pd.concat([pd_dis, pd_disease.loc[(pd_disease['disease'] == d) & (pd_disease['dataset_name'] == ds)]], axis = 0)\n                                 \n    # create dataset with all other diseases, target set to 0\n    pd_others = pd_disease.loc[(pd_disease['disease'] == counter_d)]\n    target_others = pd_others['disease'].apply(lambda x: 1 if x == d else 0)\n    \n    pd_train = pd.concat([pd_cont, pd_dis], axis = 0)\n    # adding control data from healthy subject, data by HMP\n    pd_train = pd.concat([pd_train, pd_control.loc[pd_control['dataset_name'] == 'hmp']], axis = 0)\n    pd_train = pd.concat([pd_train, pd_control.loc[pd_control['dataset_name'] == 'hmpii']], axis = 0)\n    target = pd_train['disease']\n    # convert text target into binary\n    binary_target = target.apply(lambda x: 1 if x == d else 0)\n    # binary_target.value_counts()\n    # use only abundance data for training\n    pd_train  = pd_train[species] \n    disease_train, disease_test, disease_y_train, disease_y_test = train_test_split(pd_train, binary_target, test_size = 0.10, random_state = test_train_split_SEED)   \n    pd_others = pd_others[species] \n    full_test = pd.concat([disease_test, pd_others])\n    full_y_test = pd.concat([disease_y_test, target_others])\n    \n    disease_y_test.value_counts()\n    disease_y_train.value_counts()\n    preds = np.zeros(disease_y_test.shape[0])\n    full_preds = np.zeros(full_y_test.shape[0])\n\n    for fold, (idxT,idxV) in enumerate(skf.split(disease_train, disease_y_train)):\n\n        X_train = disease_train.iloc[idxT]\n        X_val = disease_train.iloc[idxV]\n        y_train = disease_y_train.iloc[idxT]\n        y_val = disease_y_train.iloc[idxV]\n    \n        XGB_model = XGBClassifier(n_estimators=5000, max_depth=None, \n                            learning_rate=0.05,\n                            objective='binary:logistic', \n                            metric='auc',\n                            verbosity  = VERBOSE,\n                            # tree_method = 'gpu_hist',\n                            n_jobs=-1, random_state  = SEED                            )\n        \n        if show_fold_stats:\n            print('-' * 80)\n            print('Fold : %s'%(fold+1))\n    \n        XGB_model.fit(X_train, y_train,\n                        eval_set = [(X_val, y_val)],\n                        eval_metric=['logloss'],\n                        early_stopping_rounds = 100, verbose = VERBOSE )\n            \n        XGB_preds = XGB_model.predict_proba(X_val)\n        XGB_score = metrics.roc_auc_score(y_val, XGB_preds[:,1])\n        XGB_class = XGB_model.predict(X_val)\n        \n        XGB_test = XGB_model.predict_proba(disease_test)\n        XGB_test_score = metrics.roc_auc_score(disease_y_test, XGB_test[:,1])\n        XGB_test_class = XGB_model.predict(disease_test)\n        \n        full_test_preds = XGB_model.predict_proba(full_test)\n        full_test_score = metrics.roc_auc_score(full_y_test, full_test_preds[:,1])\n        full_test_class = XGB_model.predict(full_test)\n               \n        f1s = f1_score(y_val, XGB_class)\n        recall = metrics.recall_score(y_val, XGB_class)\n        precision_score = metrics.precision_score(y_val, XGB_class)\n        \n        f1_test = f1_score(disease_y_test, XGB_test_class)\n        recall_test = metrics.recall_score(disease_y_test, XGB_test_class)\n        precision_score_test = metrics.precision_score(disease_y_test, XGB_test_class)\n        \n        f1_full_test = f1_score(full_y_test, full_test_class)\n        recall_full_test = metrics.recall_score(full_y_test, full_test_class)\n        precision_full_test = metrics.precision_score(full_y_test, full_test_class)\n\n        if show_fold_stats:        \n            print('ROC AUC score for XGBoost model valid set: %.4f'%XGB_score)\n            print('F1 score: %0.4f'%f1s)\n            print(confusion_matrix(y_val, XGB_class))\n    \n            print('ROC AUC score for XGBoost model test set: %.4f'%XGB_test_score)\n            print('F1 score: %0.4f'%f1_test)\n            print(confusion_matrix(disease_y_test, XGB_test_class))\n            \n            print('ROC AUC score for full test set including other diseases used as false controls: %.4f'%full_test_score)\n            print('F1 score: %0.4f'%f1_full_test)\n            print(confusion_matrix(full_y_test, full_test_class))\n        \n        preds += XGB_test[:,1] / FOLDS\n        full_preds += full_test_preds[:,1] / FOLDS\n        \n        fold_score = [XGB_score,f1s,recall,precision_score, XGB_test_score,f1_test,recall_test,precision_score_test]\n        oof_scores.append({fold : fold_score})\n    \n    avg_test_score = metrics.roc_auc_score(disease_y_test, preds)\n    avg_class = np.where(preds < 0.5, 0, 1)\n    avg_f1_test = f1_score(disease_y_test, avg_class)\n    avg_recall_test = metrics.recall_score(disease_y_test, avg_class)\n    avg_precision_score_test = metrics.precision_score(disease_y_test, avg_class)\n\n    avg_full_test_score = metrics.roc_auc_score(full_y_test, full_preds)\n    avg_class_full = np.where(full_preds < 0.5, 0, 1)\n    avg_f1_test_full = f1_score(full_y_test, avg_class_full)\n    avg_recall_full_test = metrics.recall_score(full_y_test, avg_class_full)\n    avg_precision_full_test = metrics.precision_score(full_y_test, avg_class_full)\n\n    if show_fold_stats:        \n        print('-' * 80)\n        print('Confusion matrix for %s averaged across %i folds '%(d,FOLDS))\n        print(confusion_matrix(disease_y_test, avg_class))\n\n        print('ROC AUC score for %s averaged over %i folds: %.4f'%(d, FOLDS, avg_test_score))\n        print('F1 : %.4f, Recall : %.4f , Precision : %.4f'%(avg_f1_test, avg_recall_test, avg_precision_score_test))\n    \n    print('ROC AUC score for %s against %s averaged over %i folds : %.4f'%(d, counter_d, FOLDS, avg_full_test_score ))\n    print('F1 : %.4f, Recall : %.4f , Precision : %.4f'%(avg_f1_test_full, avg_recall_full_test, avg_precision_full_test))\n    print('Confusion matrix for %s against %s averaged across %i folds'%(d, counter_d, FOLDS))\n    print(confusion_matrix(full_y_test, avg_class_full))\n    \n    return full_preds, full_y_test, {d : (avg_test_score, avg_f1_test, avg_recall_test, avg_precision_score_test, oof_scores)}\n\n\ndef disease_prediction(d):\n    print('-' * 80)\n    print('Disease : %s'%d)\n    \n    skf = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\n    oof_preds = []\n    oof_aucs = []\n    oof_scores= []\n    ds_names = data_sets[d]\n    if len(ds_names) == 1:\n        pd_cont = pd_control.loc[pd_control['dataset_name'] == ds_names[0]]\n        pd_dis = pd_disease.loc[pd_disease['dataset_name'] == ds_names[0]]\n    else:\n        pd_cont = pd_control.loc[pd_control['dataset_name'] == ds_names[0]]\n        pd_dis = pd_disease.loc[(pd_disease['disease'] == d) & (pd_disease['dataset_name'] == ds_names[0])]\n        for ds in ds_names[1:]:\n            pd_cont = pd.concat([pd_cont, pd_control.loc[pd_control['dataset_name'] == ds]], axis = 0)\n            pd_dis = pd.concat([pd_dis, pd_disease.loc[(pd_disease['disease'] == d) & (pd_disease['dataset_name'] == ds)]], axis = 0)\n                                 \n    # create dataset with all other diseases, target set to 0\n    pd_others = pd_disease.loc[(pd_disease['disease'] != d)]\n    target_others = pd_others['disease'].apply(lambda x: 1 if x == d else 0)\n    \n    pd_train = pd.concat([pd_cont, pd_dis], axis = 0)\n    # adding control data from healthy subject, data by HMP\n    pd_train = pd.concat([pd_train, pd_control.loc[pd_control['dataset_name'] == 'hmp']], axis = 0)\n    pd_train = pd.concat([pd_train, pd_control.loc[pd_control['dataset_name'] == 'hmpii']], axis = 0)\n    target = pd_train['disease']\n    # convert text target into binary\n    binary_target = target.apply(lambda x: 1 if x == d else 0)\n    # binary_target.value_counts()\n    # use only abundance data for training\n    pd_train  = pd_train[species] \n    disease_train, disease_test, disease_y_train, disease_y_test = train_test_split(pd_train, binary_target, test_size = 0.10, random_state = test_train_split_SEED)   \n    pd_others = pd_others[species] \n    full_test = pd.concat([disease_test, pd_others])\n    full_y_test = pd.concat([disease_y_test, target_others])\n    \n    disease_y_test.value_counts()\n    disease_y_train.value_counts()\n    preds = np.zeros(disease_y_test.shape[0])\n    full_preds = np.zeros(full_y_test.shape[0])\n\n    for fold, (idxT,idxV) in enumerate(skf.split(disease_train, disease_y_train)):\n\n        X_train = disease_train.iloc[idxT]\n        X_val = disease_train.iloc[idxV]\n        y_train = disease_y_train.iloc[idxT]\n        y_val = disease_y_train.iloc[idxV]\n    \n        XGB_model = XGBClassifier(n_estimators=5000, max_depth=None, \n                            learning_rate=0.05,\n                            objective='binary:logistic', \n                            metric='auc',\n                            verbosity  = VERBOSE,\n                            # tree_method = 'gpu_hist',\n                            n_jobs=-1, random_state  = SEED                            )\n        \n        if show_fold_stats:\n            print('-' * 80)\n            print('Fold : %s'%(fold+1))\n    \n        XGB_model.fit(X_train, y_train,\n                        eval_set = [(X_val, y_val)],\n                        eval_metric=['logloss'],\n                        # eval_metric=['auc','logloss'],\n                        early_stopping_rounds = 100, verbose = VERBOSE )\n            \n        XGB_preds = XGB_model.predict_proba(X_val)\n        XGB_score = metrics.roc_auc_score(y_val, XGB_preds[:,1])\n        XGB_class = XGB_model.predict(X_val)\n        \n        XGB_test = XGB_model.predict_proba(disease_test)\n        XGB_test_score = metrics.roc_auc_score(disease_y_test, XGB_test[:,1])\n        XGB_test_class = XGB_model.predict(disease_test)\n        \n        full_test_preds = XGB_model.predict_proba(full_test)\n        full_test_score = metrics.roc_auc_score(full_y_test, full_test_preds[:,1])\n        full_test_class = XGB_model.predict(full_test)\n        \n        # (fpr, tpr, thresholds) = metrics.roc_curve(y_val, XGB_preds[:,1])\n        # plot_ROC(fpr, tpr, d)\n        \n        f1s = f1_score(y_val, XGB_class)\n        recall = metrics.recall_score(y_val, XGB_class)\n        precision_score = metrics.precision_score(y_val, XGB_class)\n        \n        f1_test = f1_score(disease_y_test, XGB_test_class)\n        recall_test = metrics.recall_score(disease_y_test, XGB_test_class)\n        precision_score_test = metrics.precision_score(disease_y_test, XGB_test_class)\n        \n        f1_full_test = f1_score(full_y_test, full_test_class)\n        recall_full_test = metrics.recall_score(full_y_test, full_test_class)\n        precision_full_test = metrics.precision_score(full_y_test, full_test_class)\n        \n        if show_fold_stats:        \n            print('ROC AUC score for XGBoost model valid set: %.4f'%XGB_score)\n            print('F1 score: %0.4f'%f1s)\n            print(confusion_matrix(y_val, XGB_class))\n    \n            print('ROC AUC score for XGBoost model test set: %.4f'%XGB_test_score)\n            print('F1 score: %0.4f'%f1_test)\n            print(confusion_matrix(disease_y_test, XGB_test_class))\n            \n            print('ROC AUC score for full test set including other diseases used as false controls: %.4f'%full_test_score)\n            print('F1 score: %0.4f'%f1_full_test)\n            print(confusion_matrix(full_y_test, full_test_class))\n\n        preds += XGB_test[:,1] / FOLDS\n        full_preds += full_test_preds[:,1] / FOLDS\n        \n        fold_score = [XGB_score,f1s,recall,precision_score, XGB_test_score,f1_test,recall_test,precision_score_test]\n        oof_scores.append({fold : fold_score})\n    \n    avg_test_score = metrics.roc_auc_score(disease_y_test, preds)\n    avg_class = np.where(preds < 0.5, 0, 1)\n    avg_f1_test = f1_score(disease_y_test, avg_class)\n    avg_recall_test = metrics.recall_score(disease_y_test, avg_class)\n    avg_precision_score_test = metrics.precision_score(disease_y_test, avg_class)\n\n    avg_full_test_score = metrics.roc_auc_score(full_y_test, full_preds)\n    avg_class_full = np.where(full_preds < 0.5, 0, 1)\n    avg_f1_test_full = f1_score(full_y_test, avg_class_full)\n    avg_recall_full_test = metrics.recall_score(full_y_test, avg_class_full)\n    avg_precision_full_test = metrics.precision_score(full_y_test, avg_class_full)\n\n    print('-' * 80)\n    print('Confusion matrix for %s averaged across %i folds '%(d,FOLDS))\n    print(confusion_matrix(disease_y_test, avg_class))\n\n    print('Averaged over %i folds ROC AUC score for %s: %.4f'%(FOLDS,d,avg_test_score))\n    print('F1 : %.4f, Recall : %.4f , Precision : %.4f'%(avg_f1_test, avg_recall_test, avg_precision_score_test))\n    \n    print('Averaged over %i folds ROC AUC score for %s against full set of other diseases: %.4f'%(FOLDS,d,avg_full_test_score))\n    print('F1 : %.4f, Recall : %.4f , Precision : %.4f'%(avg_f1_test_full, avg_recall_full_test, avg_precision_full_test))\n    print('Confusion matrix for %s averaged across %i folds for full set'%(d,FOLDS))\n    print(confusion_matrix(full_y_test, avg_class_full))\n    \n    return preds, disease_y_test, full_preds, full_y_test\n    # return preds, disease_y_test, {d : (avg_test_score, avg_f1_test, avg_recall_test, avg_precision_score_test, oof_scores)}, full_preds, full_y_test\n\n","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEEDs = [1969,1970,1971,1972,2020,2021]        \nd = 'cirrhosis'\n# SEED = 1970\nd_preds = []\ndf_preds = []\ndc_preds = []\nfor SEED in SEEDs:\n    print('=' * 80)\n    print('Seed : %i'%SEED)\n    d_pred, y_true, full_preds, full_y_test = disease_prediction(d) \n    d_preds.append(d_pred)\n    df_preds.append(full_preds)\n\n#     for counter in diseases:\n#         if counter != d:\n#             dc_pred, y_preds, _ = disease_distinction(d, counter)\n\n# print('-' * 80)","execution_count":26,"outputs":[{"output_type":"stream","text":"================================================================================\nSeed : 1969\n--------------------------------------------------------------------------------\nDisease : cirrhosis\nAveraged over 5 folds ROC AUC score for cirrhosis against full set of other diseases: 0.9915\nF1 : 0.4471, Recall : 0.9500 , Precision : 0.2923\nConfusion matrix for cirrhosis averaged across 5 folds for full set\n[[815  46]\n [  1  19]]\n================================================================================\nSeed : 1970\n--------------------------------------------------------------------------------\nDisease : cirrhosis\nAveraged over 5 folds ROC AUC score for cirrhosis against full set of other diseases: 0.9911\nF1 : 0.4471, Recall : 0.9500 , Precision : 0.2923\nConfusion matrix for cirrhosis averaged across 5 folds for full set\n[[815  46]\n [  1  19]]\n================================================================================\nSeed : 1971\n--------------------------------------------------------------------------------\nDisease : cirrhosis\nAveraged over 5 folds ROC AUC score for cirrhosis against full set of other diseases: 0.9917\nF1 : 0.4872, Recall : 0.9500 , Precision : 0.3276\nConfusion matrix for cirrhosis averaged across 5 folds for full set\n[[822  39]\n [  1  19]]\n================================================================================\nSeed : 1972\n--------------------------------------------------------------------------------\nDisease : cirrhosis\nAveraged over 5 folds ROC AUC score for cirrhosis against full set of other diseases: 0.9914\nF1 : 0.4750, Recall : 0.9500 , Precision : 0.3167\nConfusion matrix for cirrhosis averaged across 5 folds for full set\n[[820  41]\n [  1  19]]\n================================================================================\nSeed : 2020\n--------------------------------------------------------------------------------\nDisease : cirrhosis\nAveraged over 5 folds ROC AUC score for cirrhosis against full set of other diseases: 0.9910\nF1 : 0.4578, Recall : 0.9500 , Precision : 0.3016\nConfusion matrix for cirrhosis averaged across 5 folds for full set\n[[817  44]\n [  1  19]]\n================================================================================\nSeed : 2021\n--------------------------------------------------------------------------------\nDisease : cirrhosis\nAveraged over 5 folds ROC AUC score for cirrhosis against full set of other diseases: 0.9921\nF1 : 0.5000, Recall : 0.9500 , Precision : 0.3393\nConfusion matrix for cirrhosis averaged across 5 folds for full set\n[[824  37]\n [  1  19]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Averaged predictions across %i seeds'%len(SEEDs))\navg_pred = np.array(d_preds).mean(axis= 0)\navg_class = np.where(avg_pred < 0.5, 0, 1)\nprint('Confusion matrix for %s'%d)\nprint(confusion_matrix(y_true, avg_class))\n\navg_pred = np.array(df_preds).mean(axis= 0)\navg_class = np.where(avg_pred < 0.5, 0, 1)\nprint('Confusion matrix for %s against controls and other diseases combined'%d)\nprint(confusion_matrix(full_y_test, avg_class))\nprint('F1 score : %.4f'%f1_score(full_y_test, avg_class))","execution_count":27,"outputs":[{"output_type":"stream","text":"Averaged predictions across 6 seeds\nConfusion matrix for cirrhosis\n[[23  0]\n [ 1 19]]\nConfusion matrix for cirrhosis against controls and other diseases combined\n[[819  42]\n [  1  19]]\nF1 score : 0.4691\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"dc_preds = []\nfor SEED in SEEDs:\n    print('=' * 80)\n    print('Seed : %i'%SEED)\n\n    for counter in diseases:\n        if counter != d:\n            dc_pred, y_preds, _ = disease_distinction(d, counter)\n\n    dc_preds.append(dc_pred)","execution_count":null,"outputs":[{"output_type":"stream","text":"================================================================================\nSeed : 1969\n--------------------------------------------------------------------------------\nDiscriminate cirrhosis from obesity\n--------------------------------------------------------------------------------\nConfusion matrix for cirrhosis averaged across 5 folds \n[[23  0]\n [ 1 19]]\nROC AUC score for cirrhosis averaged over 5 folds: 1.0000\nF1 : 0.9744, Recall : 0.9500 , Precision : 1.0000\nROC AUC score for cirrhosis against obesity averaged over 5 folds : 0.9995\nF1 : 0.9500, Recall : 0.9500 , Precision : 0.9500\nConfusion matrix for cirrhosis against obesity averaged across 5 folds\n[[186   1]\n [  1  19]]\n--------------------------------------------------------------------------------\nDiscriminate cirrhosis from t2d\n--------------------------------------------------------------------------------\nConfusion matrix for cirrhosis averaged across 5 folds \n[[23  0]\n [ 1 19]]\nROC AUC score for cirrhosis averaged over 5 folds: 1.0000\nF1 : 0.9744, Recall : 0.9500 , Precision : 1.0000\nROC AUC score for cirrhosis against t2d averaged over 5 folds : 0.9858\nF1 : 0.6441, Recall : 0.9500 , Precision : 0.4872\nConfusion matrix for cirrhosis against t2d averaged across 5 folds\n[[226  20]\n [  1  19]]\n--------------------------------------------------------------------------------\nDiscriminate cirrhosis from cancer\n--------------------------------------------------------------------------------\nConfusion matrix for cirrhosis averaged across 5 folds \n[[23  0]\n [ 1 19]]\nROC AUC score for cirrhosis averaged over 5 folds: 1.0000\nF1 : 0.9744, Recall : 0.9500 , Precision : 1.0000\nROC AUC score for cirrhosis against cancer averaged over 5 folds : 0.9852\nF1 : 0.8444, Recall : 0.9500 , Precision : 0.7600\nConfusion matrix for cirrhosis against cancer averaged across 5 folds\n[[65  6]\n [ 1 19]]\n================================================================================\nSeed : 1970\n--------------------------------------------------------------------------------\nDiscriminate cirrhosis from obesity\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}